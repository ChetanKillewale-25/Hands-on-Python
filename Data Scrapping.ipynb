{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ccd85415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rural Medical Clinic\n",
      "HealthOne - Manilla\n",
      "Manilla Health Service\n",
      "Barraba Medical Centre\n",
      "Barber Street Practice\n",
      "Northwest Family Medical\n",
      "Gunnedah General Practice\n",
      "Windmill Practice\n",
      "Peel Health Care\n",
      "Barton Lane Practice\n"
     ]
    }
   ],
   "source": [
    "# DATA SCRAPPING\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "html_text = requests.get(\"https://www.healthdirect.gov.au/australian-health-services/search/new-mexico-2346-nsw/gp-general-practice/788007007\").text\n",
    "soup = BeautifulSoup(html_text,'lxml')\n",
    "jobs = soup.find_all('li',class_='css-1veq3mk')\n",
    "for job in jobs:\n",
    "    \n",
    "    #print(job.text)\n",
    "    job_name = job.find('a',class_='chakra-linkbox__overlay css-1chi6ox')\n",
    "    if job_name is not None:\n",
    "        print(job_name.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cd43dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rural Medical Clinic\n",
      "113 Manilla Street, MANILLA, NSW 2346\n",
      "Closed•Opens 8am tomorrow\n",
      "HealthOne - Manilla\n",
      "Manilla Mps, 112 Court Street, MANILLA, NSW 2346\n",
      "Closed•Opens 9:30am tomorrow\n",
      "Manilla Health Service\n",
      "112 Court Street, MANILLA, NSW 2346\n",
      "Closed•Opens 9am tomorrow\n",
      "Barraba Medical Centre\n",
      "8 Maude Street, BARRABA, NSW 2347\n",
      "Closed•Opens 8:30am tomorrow\n",
      "Barber Street Practice\n",
      "110 Barber Street, GUNNEDAH, NSW 2380\n",
      "Closed•Opens 8:30am tomorrow\n",
      "Northwest Family Medical\n",
      "59 Barber Street, GUNNEDAH, NSW 2380\n",
      "Closed•Opens 8:30am tomorrow\n",
      "Gunnedah General Practice\n",
      "27 MARQUIS STREET, GUNNEDAH, NSW 2380\n",
      "Closed•Opens 8am tomorrow\n",
      "Windmill Practice\n",
      "34 Verdelho Drive, NORTH TAMWORTH, NSW 2340\n",
      "Closed•Opens 8:30am tomorrow\n",
      "Peel Health Care\n",
      "103 Peel Street, TAMWORTH, NSW 2340\n",
      "Closed•Opens 8:30am tomorrow\n",
      "Barton Lane Practice\n",
      "Tamwell Building, Ground Floor, 121 Johnston Street, TAMWORTH, NSW 2340\n",
      "Closed•Opens 8:30am tomorrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DATA SCRAPPING\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "#Requesting to the Web_Page...\n",
    "html_text = requests.get(\"https://www.healthdirect.gov.au/australian-health-services/search/new-mexico-2346-nsw/gp-general-practice/788007007\").text\n",
    "#Using BeautifulSoup to parse data from the web_document...\n",
    "soup = BeautifulSoup(html_text,'lxml')\n",
    "#Finding the main class from the Web_Page(html_document)....\n",
    "jobs = soup.find_all('li',class_='css-1veq3mk')\n",
    "#  PRINTING THE VALUES.....\n",
    "\"\"\"for job in jobs:\n",
    "    #print(job.text)\n",
    "    job_time = job.find('div',class_='css-70qvj9')\n",
    "    job_loc = job.find('p',class_='chakra-text css-12a66f')\n",
    "    job_name = job.find('a',class_='chakra-linkbox__overlay css-1chi6ox')\n",
    "    if job_name is not None:\n",
    "        print(f\"Name: {job_name.text}\")\n",
    "    if job_loc is not None:\n",
    "        print(f\"Location: {job_loc.text}\")\n",
    "    if job_time is not None:\n",
    "        print(f\"OPening Time: {job_time.text}\")\n",
    "    \"\"\"\n",
    "def make_csv():#   WRITTING A CSV-file....\n",
    "    table = soup.find_all('li',class_='css-1veq3mk')\n",
    "    doctors = []\n",
    "    for row in table:\n",
    "        doctor = {}\n",
    "        \n",
    "        name = row.find(\"a\", class_=\"chakra-linkbox__overlay css-1chi6ox\")\n",
    "        if name is not None:\n",
    "            doctor[\"Clinic_Name\"]=name.text\n",
    "            print(name.text)\n",
    "   \n",
    "        loc = row.find(\"p\", class_=\"chakra-text css-12a66f\")\n",
    "        if loc is not None:\n",
    "            doctor[\"Location\"]=loc.text\n",
    "            print(loc.text)\n",
    "        \n",
    "        time = row.find(\"div\", class_=\"css-70qvj9\")\n",
    "        if time is not None:\n",
    "            doctor[\"Standard_Time\"]=time.text\n",
    "            print(time.text)\n",
    "        doctors.append(doctor)\n",
    "        \n",
    "    with open(\"doctors.csv\", \"w\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=[\"Clinic_Name\", \"Location\", \"Standard_Time\"])\n",
    "        writer.writeheader()\n",
    "        for doctor in doctors:\n",
    "            writer.writerow(doctor)\n",
    "make_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5150bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hlink': 'https://www.healthdirect.gov.au/australian-health-services/search/new-mexico-2346-nsw/gp-general-practice/788007007', 'id': 'li', 'class_': 'css-1veq3mk', 'details': [{'id': 'a', 'class_': 'chakra-linkbox__overlay css-1chi6ox'}, {'id': 'p', 'class_': 'chakra-text css-12a66f'}, {'id': 'div', 'class_': 'css-70qvj9'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#Requesting to the Web_Page...\\nhtml_text = requests.get(datas[\\'hlink\\']).text\\n#Using BeautifulSoup to parse data from the web_document...\\nsoup = BeautifulSoup(html_text,\\'lxml\\')\\n#Finding the main class from the Web_Page(html_document)....\\njobs = soup.find_all(datas[\"id\"],class_=datas[\\'class_\\'])\\n#print(jobs)\\nprint(f\\'\"{datas[\"details\"][1][\"class_\"]}\"\\')\\n\\nfor job in jobs:\\n    for i in range(0,len(datas[\\'details\\'])):\\n        job_ = job.find({datas[\"details\"][i][\"id\"]},class_={datas[\"details\"][i][\"class_\"]})\\n\\n        if job_ is not None and i==0:\\n            doctor[\"Clinic_Name\"]=job_.text\\n            #print(job_.text)\\n   \\n        if job_ is not None and i==1:\\n            doctor[\"Location\"]=job_.text\\n            #print(job_.text)\\n            \\n        if job_ is not None and i==2:\\n            doctor[\"Standard_Time\"]=job_.text\\n            #print(job_.text)\\n            doctorn=doctor.copy()\\n            \\'\\'\\'Reason to copy : It had an error : When I try to append the dictionary into the list(the list of dictionaries\\n            used for inserting the data into the csv file(after running of this(innermost) loop)), it rewrites the previous items in the list with a new one.\\'\\'\\'\\n            #doctors.append(doctorn)\\n            #print(doctors)\\n        \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  USING JSON \n",
    "\n",
    "# DATA SCRAPPING\n",
    "#import identifier.json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# READING FROM THE JSON FILE...\n",
    "with open('identifier.json','r') as file:\n",
    "    datas = json.load(file)\n",
    "print(datas)\n",
    "\"\"\"\n",
    "#Requesting to the Web_Page...\n",
    "html_text = requests.get(datas['hlink']).text\n",
    "#Using BeautifulSoup to parse data from the web_document...\n",
    "soup = BeautifulSoup(html_text,'lxml')\n",
    "#Finding the main class from the Web_Page(html_document)....\n",
    "jobs = soup.find_all(datas[\"id\"],class_=datas['class_'])\n",
    "#print(jobs)\n",
    "print(f'\"{datas[\"details\"][1][\"class_\"]}\"')\n",
    "\n",
    "for job in jobs:\n",
    "    for i in range(0,len(datas['details'])):\n",
    "        job_ = job.find({datas[\"details\"][i][\"id\"]},class_={datas[\"details\"][i][\"class_\"]})\n",
    "\n",
    "        if job_ is not None and i==0:\n",
    "            doctor[\"Clinic_Name\"]=job_.text\n",
    "            #print(job_.text)\n",
    "   \n",
    "        if job_ is not None and i==1:\n",
    "            doctor[\"Location\"]=job_.text\n",
    "            #print(job_.text)\n",
    "            \n",
    "        if job_ is not None and i==2:\n",
    "            doctor[\"Standard_Time\"]=job_.text\n",
    "            #print(job_.text)\n",
    "            doctorn=doctor.copy()\n",
    "            '''Reason to copy : It had an error : When I try to append the dictionary into the list(the list of dictionaries\n",
    "            used for inserting the data into the csv file(after running of this(innermost) loop)), it rewrites the previous items in the list with a new one.'''\n",
    "            #doctors.append(doctorn)\n",
    "            #print(doctors)\n",
    "        \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23c0c3cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15996/2295931613.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mextract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15996/2295931613.py\u001b[0m in \u001b[0;36mextract_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                     \u001b[0mjob_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mjob_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#  USING JSON \n",
    "\n",
    "# DATA SCRAPPING\n",
    "#import identifier.json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_data():\n",
    "    # READING FROM THE JSON FILE...\n",
    "    with open('identifier.json','r') as file:\n",
    "        datas = json.load(file)\n",
    "    #print(datas)\n",
    "    html_text = requests.get(datas[0]['url']).text\n",
    "    soup = BeautifulSoup(html_text,'lxml')\n",
    "    jobs = soup.find_all(datas[0]['id'],class_=datas[0]['parent_container'])\n",
    "    for job in jobs:\n",
    "        for data in datas:\n",
    "            for i in range(0,len(data['fields'])):\n",
    "                if data['fields'][i]['type']==\"text\":\n",
    "                    job_ = job.find(data[i]['fields']['id'],class_=data[i]['fields']['class_'])\n",
    "                    if job_ is not None:\n",
    "                        print(job.text)        \n",
    "\n",
    "extract_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bb79ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "with open('identifier.json','r') as file:\n",
    "    data = json.load(file)\n",
    "id = datas[\"details\"][0][\"id\"]\n",
    "print(f'\"{datas[\"details\"][0][\"id\"]}\"')\n",
    "print(len(datas['details']))\n",
    "\n",
    "for job in jobs:\n",
    "    for i in range(0,len(datas['details'])):\n",
    "        job_ = job.find({datas[\"details\"][i][\"id\"]},class_={datas[\"details\"][i][\"class_\"]})\n",
    "        if job_ is not None:    \n",
    "            print(job_.text)\n",
    "\n",
    "with open('doctors.csv','w',encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file,fieldnames=['Clinic_Name','Location','Standard_Time'])\n",
    "    writer.writeheader()\n",
    "    for d in doctors:\n",
    "        writer.writerow(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
